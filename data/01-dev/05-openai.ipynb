{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ebc6ed8",
   "metadata": {},
   "source": [
    "## OpenAI (ChatGPT)\n",
    "\n",
    "Beispiel für die Erstellung einer Python Applikation\n",
    "\n",
    "Zuerst muss der Open AI API Key erstellt und ein Guthaben bereitgestellt werden:\n",
    "* [API Key erstellen](https://platform.openai.com/account/api-keys)\n",
    "* [Guthaben bereitstellen](https://platform.openai.com/settings/organization/billing/overview)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9e0c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578d3b62",
   "metadata": {},
   "source": [
    "Um den Prozess zu automatisieren, erstellen wir eine Funktion, die eine neue Benutzeranfrage entgegennimmt, sie an die KI sendet und die Antwort zurückgibt.\n",
    "\n",
    "Allgemeine Anweisungen, wie Output im Markdown-Format etc., geben wir in `messages` mit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a0cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI-Client initialisieren\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Konversationsverlauf starten\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": '''\n",
    "    Bitte formatiere die Antwort im Markdown-Format\n",
    "    Verwende Schweizer Schriftsprache bei den Antworten\n",
    "    '''}\n",
    "]\n",
    "\n",
    "def chat_with_openai(user_input, messages, client):\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages\n",
    "    )\n",
    "    assistant_message = response.choices[0].message.content\n",
    "    messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "    return assistant_message\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3003925a",
   "metadata": {},
   "source": [
    "Ein Beispielaufruf sieht dann wie folgt aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Wie unterscheidet sich Prozessoptimierung von Prozessmanagement?\"\n",
    "\n",
    "response = chat_with_openai(user_input, messages, client)\n",
    "\n",
    "# Antwort anzeigen\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40927f1",
   "metadata": {},
   "source": [
    "- - -\n",
    "\n",
    "## Prompts um eine Webabwendung zu erstellen\n",
    "\n",
    "Als erstes brauchen wir eine Funktion `parse_response_to_files` um den Output von OpenAI in Dateien umzuwandeln\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8efe7b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def parse_response_to_files(response_text: str, output_dir=\"webshop\"):\n",
    "    \"\"\"\n",
    "    Parst OpenAI Markdown-Antworten und extrahiert Dateinamen + zugehörige Codeblöcke.\n",
    "    Erkennt sowohl '### ... (filename.ext)' als auch '#### filename.ext'.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Nur zulässige Dateinamen erkennen\n",
    "    valid_extensions = (\".py\", \".sh\", \".json\", \".yaml\", \".yml\", \".txt\", \".env\", \".cfg\")\n",
    "    filename_pattern_1 = re.compile(r\"^#+ .*?\\(([^)]+)\\)\", re.MULTILINE)  # z.B. (Docker.customer)\n",
    "    filename_pattern_2 = re.compile(r\"^####\\s+([\\w\\-\\.]+)$\", re.MULTILINE)  # nur wenn direkt Dateiname\n",
    "\n",
    "    filenames_1 = filename_pattern_1.findall(response_text)\n",
    "    filenames_2 = [\n",
    "        fn for fn in filename_pattern_2.findall(response_text)\n",
    "        if fn == \"Dockerfile\" or fn.endswith(valid_extensions)\n",
    "    ]\n",
    "    filenames = filenames_1 + filenames_2\n",
    "\n",
    "    # Codeblöcke extrahieren\n",
    "    codeblocks = re.findall(r\"```(?:\\w+)?\\n(.*?)```\", response_text, re.DOTALL)\n",
    "\n",
    "    if len(filenames) != len(codeblocks):\n",
    "        print(\"⚠️ Anzahl der Dateinamen stimmt nicht mit Anzahl der Codeblöcke überein.\")\n",
    "        print(f\"Gefundene Dateinamen: {len(filenames)}, Codeblöcke: {len(codeblocks)}\")\n",
    "\n",
    "    written_files = []\n",
    "\n",
    "    for name, code in zip(filenames, codeblocks):\n",
    "        filepath = Path(output_dir) / name\n",
    "        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(code.strip() + \"\\n\")\n",
    "        written_files.append(str(filepath))\n",
    "\n",
    "    print(f\"✅ {len(written_files)} Dateien gespeichert:\")\n",
    "    for f in written_files:\n",
    "        print(f\"  - {f}\")\n",
    "\n",
    "    return written_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b092867",
   "metadata": {},
   "source": [
    "Die OpenAI-API ist zustandslos, was bedeutet, dass sie sich nicht an vorherige Interaktionen erinnert. \n",
    "\n",
    "Um dennoch einen Gesprächsverlauf zu simulieren, verwenden wir eine Liste (`messages`), die sowohl Benutzer- als auch KI-Nachrichten enthält.\n",
    "\n",
    "Weitere Prompts siehe [hier](https://gitlab.com/ch-mc-b/autoshop-ms/edu/chatgpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557858e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Konversationsverlauf starten\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": '''\n",
    "    Bitte formatiere die Antwort im Markdown-Format\n",
    "    Verwende Schweizer Schriftsprache bei den Antworten\n",
    "    Bitte gib mir die Codeblöcke jeweils im folgenden Format zurück:\n",
    "    ### Beschreibung (filename.py)\n",
    "    ```python\n",
    "    code\n",
    "    ```\n",
    "    '''}\n",
    "]\n",
    "\n",
    "user_input = '''\n",
    "Basierend auf den Microservices Beispiel von Eberhard Wolff schreibe mit 3 Python Scripte welche jeweils eine Webseite mit\n",
    "- Kundendaten (Customer)\n",
    "- Produktdaten (Catalog)\n",
    "- Bestellungen (Order)\n",
    "enthalten.\n",
    "Die Scripte sollen die Daten via REST-API /<service>/api und im HTML-Format /<service/ zur Verfügung stellen.\n",
    "\n",
    "Die Produkte sollen dem eines Auto Hauses mit Autos und Auto Zubehör Artikeln entsprechen.\n",
    "\n",
    "Als TCP/IP Port soll generell 8080 und die Services sollen gegen 0.0.0.0 geöffnet sein.\n",
    "'''\n",
    "\n",
    "response = chat_with_openai(user_input, messages, client)\n",
    "\n",
    "# Antwort anzeigen\n",
    "display(Markdown(response))\n",
    "parse_response_to_files(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02579a5",
   "metadata": {},
   "source": [
    "Mit dem Grundgerüst der Applikation können wir weiterfahren und das ganze als Container Images aufbereiten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f780505",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = '''\n",
    "Erstelle für die Services ein Dockerfile und eine Docker-Compose Datei.\n",
    "Bezeichne die Dockerfile mittels Docker.<service>\n",
    "'''\n",
    "\n",
    "response = chat_with_openai(user_input, messages, client)\n",
    "\n",
    "# Antwort anzeigen\n",
    "display(Markdown(response))\n",
    "parse_response_to_files(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bcd123",
   "metadata": {},
   "source": [
    "- - - \n",
    "## Applikation bauen\n",
    "\n",
    "Zum Schluss bauen wir die Applikation zusammen und \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9cfb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd webshop\n",
    "docker-compose build\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd93326",
   "metadata": {},
   "source": [
    "und starten die Applikation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea12c18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"Customer: http://$(cat ~/work/server-ip):8080/customer\"\n",
    "echo \"Catalog : http://$(cat ~/work/server-ip):8081/catalog\"\n",
    "echo \"Order   : http://$(cat ~/work/server-ip):8082/order\"\n",
    "cd webshop\n",
    "docker-compose up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539980da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

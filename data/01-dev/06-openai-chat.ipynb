{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ebc6ed8",
   "metadata": {},
   "source": [
    "## OpenAI (ChatGPT)\n",
    "\n",
    "Beispiel um gezielt Inhalte aus Vector Stores auszulesen.\n",
    "\n",
    "Zuerst muss der Open AI API Key erstellt und ein Guthaben bereitgestellt werden:\n",
    "* [API Key erstellen](https://platform.openai.com/account/api-keys)\n",
    "* [Guthaben bereitstellen](https://platform.openai.com/settings/organization/billing/overview)\n",
    "\n",
    "Mittels API Key erstellen wir den `client` welcher die Verbindung zum OpenAI API herstellt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9e0c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "import json\n",
    "from nbconvert import MarkdownExporter\n",
    "from nbconvert.preprocessors import ExtractOutputPreprocessor\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "\n",
    "key = ''\n",
    "client = OpenAI(api_key=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9363f24",
   "metadata": {},
   "source": [
    "**Anzeige der Vector Stores**\n",
    "\n",
    "Als erstes Schauen wir welche Vector Stores vorhanden sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141db3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    all_vector_stores = []\n",
    "    after = None\n",
    "\n",
    "    while True:\n",
    "        if after:\n",
    "            response = client.vector_stores.list(limit=100, after=after)\n",
    "        else:\n",
    "            response = client.vector_stores.list(limit=100)\n",
    "\n",
    "        data = response.data\n",
    "        all_vector_stores.extend(data)\n",
    "\n",
    "        # Wenn weniger als 100 Ergebnisse => keine nÃ¤chste Seite\n",
    "        if len(data) < 100:\n",
    "            break\n",
    "\n",
    "        # ID des letzten Eintrags als nÃ¤chsten Cursor setzen\n",
    "        after = data[-1].id\n",
    "\n",
    "    if all_vector_stores:\n",
    "        print(\"Deine vorhandenen Vector Stores:\")\n",
    "        for vs in all_vector_stores:\n",
    "            print(f\"- ID: {vs.id}, Name: {vs.name}, Created At: {vs.created_at}\")\n",
    "            print(f\"  - Dokumente im Vector Store: {vs.file_counts}\")\n",
    "\n",
    "        print(f\"\\nğŸ“Š Gesamtanzahl Vector Stores: {len(all_vector_stores)}\")\n",
    "    else:\n",
    "        print(\"Es wurden keine Vector Stores gefunden.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Fehler beim Auflisten der Vector Stores: {e}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7bf4ad",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Abfrage\n",
    "\n",
    "Mittels zwei Hilfsfunktionen fragen wir unser Wissen ab:\n",
    "- `get_vector_store_id_by_name` - Gibt die ID eines Vector Stores anhand seines Namens zurÃ¼ck.\n",
    "- `query_vector_store` - FÃ¼hrt eine semantische Suche im Vector Store durch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd134a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store_id_by_name(target_name):\n",
    "    try:\n",
    "        after = None\n",
    "        target_name_lower = target_name.lower()\n",
    "\n",
    "        while True:\n",
    "            # Abrufen mit oder ohne Cursor\n",
    "            if after:\n",
    "                response = client.vector_stores.list(limit=100, after=after)\n",
    "            else:\n",
    "                response = client.vector_stores.list(limit=100)\n",
    "\n",
    "            for vs in response.data:\n",
    "                if vs.name.lower() == target_name_lower:\n",
    "                    return vs.id\n",
    "\n",
    "            # Wenn weniger als 100 Ergebnisse => keine weitere Seite\n",
    "            if len(response.data) < 100:\n",
    "                break\n",
    "\n",
    "            # Cursor fÃ¼r nÃ¤chste Seite setzen\n",
    "            after = response.data[-1].id\n",
    "\n",
    "        print(f\"Kein Vector Store mit dem Namen '{target_name}' gefunden.\")\n",
    "        return None\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler beim Abrufen der Vector Stores: {e}\")\n",
    "        return None\n",
    "\n",
    "def query_vector_store(vector_store_id, query, top_k=3):\n",
    "    try:\n",
    "        response = client.responses.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            input=query,\n",
    "            tools=[{\n",
    "                \"type\": \"file_search\",\n",
    "                \"vector_store_ids\": [vector_store_id]\n",
    "            }]\n",
    "        )\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei der Suche im Vector Store: {e}\")\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e139e3ac",
   "metadata": {},
   "source": [
    "Dann folgt die eigentliche Abfrage:\n",
    "- `vector_store_name`- Name des Vector Stores\n",
    "- `user_input`- die eigentliche Frage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabad552",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store_name = \"m300-BiVo2021\"\n",
    "user_input = \"was wird in diesem modul unterrichtet?\"\n",
    "\n",
    "# FÃ¼hre eine Suche im Vector Store durch\n",
    "vector_store_id = get_vector_store_id_by_name(vector_store_name)\n",
    "response = query_vector_store(vector_store_id, user_input)\n",
    "\n",
    "# Extrahiere den Markdown-Text aus der Antwort\n",
    "if response:\n",
    "    # response.output enthÃ¤lt eine Liste mit Nachrichten\n",
    "    for item in response.output:\n",
    "        if item.type == \"message\" and hasattr(item, \"content\"):\n",
    "            for content_item in item.content:\n",
    "                if content_item.type == \"output_text\" and hasattr(content_item, \"text\"):\n",
    "                    markdown_text = content_item.text\n",
    "                    display(Markdown(markdown_text))\n",
    "                    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d0063b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Debug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677e9f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatiertes JSON anzeigen (z.â€¯B. zum Debuggen)\n",
    "if response:\n",
    "    # Versuche, das Response-Objekt in ein dict zu konvertieren, falls nÃ¶tig\n",
    "    if hasattr(response, 'model_dump'):\n",
    "        response_dict = response.model_dump()  # bei pydantic-basierten Objekten\n",
    "    else:\n",
    "        response_dict = response  # falls es schon ein dict ist\n",
    "\n",
    "    # Formatiert anzeigen\n",
    "    print(json.dumps(response_dict, indent=2, ensure_ascii=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf075816",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ai)",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
